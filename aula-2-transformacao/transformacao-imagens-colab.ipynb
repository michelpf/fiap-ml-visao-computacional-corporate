{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformação de imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Atenção: este notebook foi desenhado para funcionar no **Google Collab**. Se pretende executar localmente prefira a versão local deste notebook, sem o sufixo ```-collab```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Requerimentos\n",
    "\n",
    "Utilize o comando ao lado para instalar pelo Anaconda terminal.\n",
    "\n",
    "* OpenCV 3.4.3 (```conda install -c conda-forge opencv==3.4.3```)\n",
    "* Matplotlib 3.1.3 (```conda install matplotlib==3.1.3```)\n",
    "* Seaborn 0.0.10 (```conda install -c conda-forge seaborn==0.10.0```)\n",
    "* Numpy 1.18.1 (```conda install numpy==1.15.2```)\n",
    "\n",
    "### 1.2 Arquivos\n",
    "\n",
    "Baixe o repositório do GitHub utilizando o comando abaixo. Em caso de atualização, utilize o comando para apagar o diretório antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf fiap-ml-visao-computacional/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/michelpf/fiap-ml-visao-computacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora posicionar o diretório do repositório para a aula respectiva. Nesse caso envie o comando de mudança de diretório."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd fiap-ml-visao-computacional/aula-2-transformacao/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação das bibliotecas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "\n",
    "#Exibição na mesma tela do Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Translação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando uma imagem previamente existente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem = cv2.imread(\"imagens/robot.jpg\")\n",
    "imagem = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(imagem)\n",
    "plt.title(\"Robô\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando translação, sempre em paralelo nos eixos x e y. Neste caso utilizando valores positivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = imagem.shape[:2]\n",
    "\n",
    "#Vamos alterar o tamanho para a 25% do original\n",
    "height_alterado, width_alterado = height/4, width/4\n",
    "\n",
    "# Matriz de translação\n",
    "matriz_translacao = np.float32([[1, 0, width_alterado],[0, 1, height_alterado]])\n",
    "\n",
    "print(matriz_translacao)\n",
    "\n",
    "imagem_transladada = cv2.warpAffine(imagem, matriz_translacao, (width, height))\n",
    "\n",
    "plt.imshow(imagem_transladada)\n",
    "plt.title(\"Robô Translação\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando translação no sentido inverso, utilizando valores negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_translacao = np.float32([[1, 0, -width_alterado],[0, 1, -height_alterado]])\n",
    "\n",
    "# Matriz de translação\n",
    "print(matriz_translacao)\n",
    "\n",
    "imagem_transalada = cv2.warpAffine(imagem, matriz_translacao, (width, height))\n",
    "\n",
    "plt.imshow(imagem_transalada)\n",
    "plt.title(\"Robô Translação\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Rotação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando uma imagem previamente existente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem = cv2.imread(\"imagens/robot.jpg\")\n",
    "imagem = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(imagem)\n",
    "plt.title(\"Robô\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando matriz de rotação e incluindo na transformação afim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = imagem.shape[:2]\n",
    "matriz_rotacao = cv2.getRotationMatrix2D((width/2, height/2), 90, 1)\n",
    "imagem_rotacionada = cv2.warpAffine(imagem, matriz_rotacao, (width, height))\n",
    "\n",
    "print(matriz_rotacao)\n",
    "\n",
    "plt.imshow(imagem_rotacionada)\n",
    "plt.title(\"Robô Rotacionado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando transposição de imagens. Método mais simples para rotações de ângulos retos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_transposta = cv2.transpose(imagem)\n",
    "\n",
    "plt.imshow(imagem_rotacionada)\n",
    "plt.title(\"Robô Rotacionado (por transposição)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Redimensionamento e Interpolação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O redimensionamento de imagens pode utilizar uma série de interpolações que servem para cobrir os pixels que são expandidos. Cada tipo de interpolação traz aspectos de maior nitidez e velocidade de processamento.\n",
    "\n",
    "*Os experimentos abaixo foram adaptados deste [link](http://tanbakuchi.com/posts/comparison-of-openv-interpolation-algorithms), de Anthony Tanbakuchi.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando uma imagem previamente existente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem = cv2.imread(\"imagens/coffee_small.jpg\")\n",
    "imagem = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(imagem)\n",
    "plt.title(\"Café Original (Pequeno)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escala por fator (multiplicação)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fator_x=5\n",
    "fator_y=5\n",
    "\n",
    "imagem_nova_linear = cv2.resize(imagem, None, fx=fator_x, fy=fator_y)\n",
    "imagem_nova_cubica = cv2.resize(imagem, None, fx=fator_x, fy=fator_y, interpolation=cv2.INTER_CUBIC)\n",
    "imagem_nova_area = cv2.resize(imagem, None, fx=fator_x, fy=fator_y, interpolation=cv2.INTER_AREA)\n",
    "imagem_nova_lanczo = cv2.resize(imagem, None, fx=fator_x, fy=fator_y, interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(imagem_nova_linear)\n",
    "plt.title(\"Ampliação Linear\")\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(imagem_nova_cubica)\n",
    "plt.title(\"Ampliação Cúbica\")\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(imagem_nova_area)\n",
    "plt.title(\"Ampliação Interárea\")\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(imagem_nova_lanczo)\n",
    "plt.title(\"Ampliação Lanczo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escala por novo tamanho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novo_tamanho = (200,200)\n",
    "\n",
    "imagem_nova_linear = cv2.resize(imagem, novo_tamanho)\n",
    "imagem_nova_cubica = cv2.resize(imagem, novo_tamanho, interpolation=cv2.INTER_CUBIC)\n",
    "imagem_nova_interarea = cv2.resize(imagem, novo_tamanho, interpolation=cv2.INTER_AREA)\n",
    "imagem_nova_lanczo = cv2.resize(imagem, novo_tamanho, interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(imagem_nova_linear)\n",
    "plt.title(\"Ampliação Linear\")\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(imagem_nova_cubica)\n",
    "plt.title(\"Ampliação Cúbica\")\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(imagem_nova_interarea)\n",
    "plt.title(\"Ampliação Interárea\")\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(imagem_nova_lanczo)\n",
    "plt.title(\"Ampliação Lanczo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Transformação Homográfica (Não-Afim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem = cv2.imread(\"imagens/portal.jpg\")\n",
    "imagem = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(imagem)\n",
    "plt.title(\"Portal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = imagem.shape[:2]\n",
    "\n",
    "imagem_marcadores = imagem.copy()\n",
    "\n",
    "print(height, width)\n",
    "\n",
    "pontos_marcadores = np.float32([[300,90],[510,100],[20,490],[780,490]])\n",
    "pontos_destino = np.float32([[0,0],[800,0],[0,600],[800,600]])\n",
    "\n",
    "# Adicionando marcadores para visualizar os pontos que serão expandidos\n",
    "\n",
    "cv2.circle(imagem_marcadores, (300,90), 5, (0, 0, 255), 3)\n",
    "cv2.circle(imagem_marcadores, (510,100), 5, (0, 0, 255), 3)\n",
    "cv2.circle(imagem_marcadores, (20,490), 5, (0, 0, 255), 3)\n",
    "cv2.circle(imagem_marcadores, (780,490), 5, (0, 0, 255), 3)\n",
    "\n",
    "plt.imshow(imagem_marcadores)\n",
    "plt.title(\"Portal com Marcadores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando a transformação não afim\n",
    "\n",
    "matriz_perspectiva = cv2.getPerspectiveTransform(pontos_marcadores, pontos_destino)\n",
    "imagem_transformada = cv2.warpPerspective(imagem,matriz_perspectiva,(800,600))\n",
    "\n",
    "plt.imshow(imagem_transformada)\n",
    "plt.title(\"Portal com Marcadores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Recorte de imagens e região de interesse (ROI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No OpenCV não existe uma função própria para recortar segmentos de uma imagem. Por outro lado, conseguimos fazer esta tarefa fácilmente aplicando diretamente na matriz da imagem as alterações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem = cv2.imread(\"imagens/robot.jpg\")\n",
    "imagem = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "height, width = imagem.shape[:2]\n",
    "\n",
    "plt.imshow(imagem)\n",
    "plt.title(\"Imagem Original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linha_inicio, coluna_inicio = int(height*0.3), int(width*0.3)\n",
    "linha_final, coluna_final =  int(height*0.6), int(width*0.6)\n",
    "\n",
    "imagem_recortada = imagem[linha_inicio:linha_final, coluna_inicio:coluna_final]\n",
    "\n",
    "plt.imshow(imagem_recortada)\n",
    "plt.title(\"Imagem Recortada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Obtendo imagem a da câmera\n",
    "\n",
    "Este método é de uso exclusivo do Colab, uma vez que não temos acesso direto a câmera do dispositivo.\n",
    "\n",
    "Obtido dos [snippets avançados](https://colab.research.google.com/notebooks/snippets/advanced_outputs.ipynb#scrollTo=buJCl90WhNfq) do Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Javascript\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "\n",
    "def take_photo(filename='photo.jpg', quality=0.8):\n",
    "  js = Javascript('''\n",
    "    async function takePhoto(quality) {\n",
    "      const div = document.createElement('div');\n",
    "      const capture = document.createElement('button');\n",
    "      capture.textContent = 'Capture';\n",
    "      div.appendChild(capture);\n",
    "\n",
    "      const video = document.createElement('video');\n",
    "      video.style.display = 'block';\n",
    "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "\n",
    "      document.body.appendChild(div);\n",
    "      div.appendChild(video);\n",
    "      video.srcObject = stream;\n",
    "      await video.play();\n",
    "\n",
    "      // Resize the output to fit the video element.\n",
    "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
    "\n",
    "      // Wait for Capture to be clicked.\n",
    "      await new Promise((resolve) => capture.onclick = resolve);\n",
    "\n",
    "      const canvas = document.createElement('canvas');\n",
    "      canvas.width = video.videoWidth;\n",
    "      canvas.height = video.videoHeight;\n",
    "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
    "      stream.getVideoTracks()[0].stop();\n",
    "      div.remove();\n",
    "      return canvas.toDataURL('image/jpeg', quality);\n",
    "    }\n",
    "    ''')\n",
    "  display(js)\n",
    "  data = eval_js('takePhoto({})'.format(quality))\n",
    "  binary = b64decode(data.split(',')[1])\n",
    "  with open(filename, 'wb') as f:\n",
    "    f.write(binary)\n",
    "  return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função que obtem a foto da câmera do navegador e salva em uma pasta determinada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "try:\n",
    "  filename = take_photo(\"imagens/foto.jpg\")\n",
    "  print('Saved to {}'.format(filename))\n",
    "  \n",
    "  # Show the image which was just taken.\n",
    "  display(Image(filename))\n",
    "except Exception as err:\n",
    "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
    "  # grant the page permission to access it.\n",
    "  print(str(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem = cv2.imread(\"imagens/foto.jpg\")\n",
    "imagem = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(imagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_anotada = imagem.copy()\n",
    "cv2.rectangle(imagem_anotada,(1000,600), (1400,1000), (255, 0, 0), 2)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(imagem_anotada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = imagem_anotada[600:1000, 1000:1400]\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "roi = cv2.cvtColor(roi, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "imagem_anotada[600:1000, 1000:1400] = roi\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(imagem_anotada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Alterando brilho (nitidez) de uma imagem\n",
    "\n",
    "Refere-se a tornar a imagem mais clara."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem = cv2.imread(\"imagens/robot.jpg\")\n",
    "imagem = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "imagem_shape = imagem.shape\n",
    "\n",
    "plt.imshow(imagem)\n",
    "plt.title(\"Imagem Original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_brilho = np.ones(imagem_shape, np.uint8) * 100\n",
    "imagem_brilho = cv2.add(imagem, matriz_brilho)\n",
    "\n",
    "plt.imshow(imagem_brilho)\n",
    "plt.title(\"Imagem Brilho\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_escura = cv2.subtract(imagem, matriz_brilho)\n",
    "\n",
    "plt.imshow(imagem_escura)\n",
    "plt.title(\"Imagem Escura\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Operações lógicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As operações lógicas ou bitwise operations são operações do tipo and, or, xor e not. São utilizadas na composição de 2 imagens, criar máscaras e intersecções."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retangulo = np.zeros((300,300), np.uint8)\n",
    "cv2.rectangle(retangulo, (50,50), (200,200), 255, -2)\n",
    "\n",
    "plt.imshow(retangulo, cmap=\"gray\")\n",
    "plt.title(\"Retangulo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circulo = np.zeros((300,300), np.uint8)\n",
    "cv2.circle(circulo,(180,150), 100, 255, -2)\n",
    "\n",
    "plt.imshow(circulo, cmap=\"gray\")\n",
    "plt.title(\"Círculo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operacao_and = cv2.bitwise_and(retangulo, circulo)\n",
    "\n",
    "plt.imshow(operacao_and, cmap=\"gray\")\n",
    "plt.title(\"Operação And (E)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operacao_or = cv2.bitwise_or(retangulo, circulo)\n",
    "\n",
    "plt.imshow(operacao_or, cmap=\"gray\")\n",
    "plt.title(\"Operação Or (Ou)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operacao_xor = cv2.bitwise_xor(retangulo, circulo)\n",
    "\n",
    "plt.imshow(operacao_or, cmap=\"gray\")\n",
    "plt.title(\"Operação Xor (Ou Exclusivo)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operacao_negacao = cv2.bitwise_not(circulo)\n",
    "\n",
    "plt.imshow(operacao_negacao, cmap=\"gray\")\n",
    "plt.title(\"Operação Not (Negação)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
